{
 "metadata": {
  "name": "",
  "signature": "sha256:b1260ef516f48cc2663e15327b636490a21a88df7442466ae6b59278b5d58195"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "SVM - Linear Classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "import numpy as np\n",
      "from IPython.display import Latex\n",
      "%pylab inline\n",
      "import pylab as plt\n",
      "import scipy\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate some sample data\n",
      "X = [[0, 0], [1, 1]]\n",
      "y = [-1, 1]\n",
      "# create the classifier - SVC: Support Vector Classification\n",
      "# set probability = True to get probabilistic predictions\n",
      "clf = svm.SVC(probability=True)\n",
      "# training the classifier\n",
      "clf.fit(X, y)  \n",
      "# predict on unseen data using the trained classifier\n",
      "p = clf.predict([[-2., -2.]])\n",
      "p1 = clf.predict_proba([[0,0]])\n",
      "print p\n",
      "print p1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Case 1: Training data is linearly separable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate training data\n",
      "mean1 = [4,4]\n",
      "mean2 = [1,1]\n",
      "cov = [[1,-0.8],[-0.8,1]]\n",
      "x11,x12 = np.random.multivariate_normal(mean1,cov,20).T\n",
      "x21,x22 = np.random.multivariate_normal(mean2,cov,20).T\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "plt.xlim([-2,8])\n",
      "plt.ylim([-2,8])\n",
      "#plt.axis('equal'); \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prepare training data\n",
      "X = np.vstack([np.array([x11,x12]).T,np.array([x21,x22]).T])\n",
      "y = np.vstack([np.ones([20,1]),-1*np.ones([20,1])])\n",
      "y = np.ravel(y)\n",
      "# retrain SVC - this time using a linear kernel\n",
      "clf = svm.SVC(kernel='linear',probability=True)\n",
      "clf.fit(X,y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Examine test data. Decision boundary is linear."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1 = np.arange(-2, 8, 0.1)\n",
      "x2 = np.arange(-2, 8, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "#ystar = clf.predict_proba(Xstar)\n",
      "#ystar = np.amax(ystar,axis=1)\n",
      "\n",
      "# accuracy\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Case 2: Training data not linearly separable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate training data\n",
      "mean = [4,4]\n",
      "cov = [[4,0],[0,4]]\n",
      "x1,x2 = np.random.multivariate_normal(mean,cov,1000).T\n",
      "X = np.array([x1,x2]).T\n",
      "pdf = scipy.stats.multivariate_normal.pdf(X,mean,cov)\n",
      "t1 = np.min(pdf) + 0.33*(np.max(pdf) - np.min(pdf))\n",
      "t2 = np.min(pdf) + 0.66*(np.max(pdf) - np.min(pdf))\n",
      "negi = pdf < t1\n",
      "posi = pdf > t2\n",
      "Xn = X[negi,]\n",
      "Xp = X[posi,]\n",
      "plt.scatter(Xn[:,0],Xn[:,1])\n",
      "plt.scatter(Xp[:,0],Xp[:,1],c='r')\n",
      "X = np.vstack([Xn,Xp])\n",
      "# true labels\n",
      "y = np.vstack([-1*np.ones([Xn.shape[0],1]),np.ones([Xp.shape[0],1])])\n",
      "y = np.ravel(y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "a. Using a Linear SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = svm.SVC(kernel='linear')\n",
      "clf.fit(X,y)\n",
      "# test on a grid\n",
      "x1 = np.arange(-5, 15, 0.1)\n",
      "x2 = np.arange(-5, 15, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "# accuracy\n",
      "plt.scatter(Xn[:,0],Xn[:,1])\n",
      "plt.scatter(Xp[:,0],Xp[:,1],c='r')\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "b. Using a Polynomial SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = svm.SVC(kernel='poly',degree=3)\n",
      "clf.fit(X,y)\n",
      "# test on a grid\n",
      "x1 = np.arange(-5, 15, 0.1)\n",
      "x2 = np.arange(-5, 15, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "# accuracy\n",
      "plt.scatter(Xn[:,0],Xn[:,1])\n",
      "plt.scatter(Xp[:,0],Xp[:,1],c='r')\n",
      "# add the predictions as a contour\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "c. Using a RBF kernel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = svm.SVC(kernel='rbf',gamma=0.1)\n",
      "clf.fit(X,y)\n",
      "# test on a grid\n",
      "x1 = np.arange(-5, 15, 0.1)\n",
      "x2 = np.arange(-5, 15, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "# accuracy\n",
      "plt.scatter(Xn[:,0],Xn[:,1])\n",
      "plt.scatter(Xp[:,0],Xp[:,1],c='r')\n",
      "# add the predictions as a contour\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Case 3: Inseparable Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate training data\n",
      "mean1 = [3,3]\n",
      "mean2 = [1,1]\n",
      "cov = [[2,-0.6],[-0.6,2]]\n",
      "x11,x12 = np.random.multivariate_normal(mean1,cov,20).T\n",
      "x21,x22 = np.random.multivariate_normal(mean2,cov,20).T\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "plt.xlim([-2,8])\n",
      "plt.ylim([-2,8])\n",
      "#plt.axis('equal'); \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prepare training data\n",
      "X = np.vstack([np.array([x11,x12]).T,np.array([x21,x22]).T])\n",
      "y = np.vstack([np.ones([20,1]),-1*np.ones([20,1])])\n",
      "y = np.ravel(y)\n",
      "\n",
      "clf = svm.SVC(kernel='rbf',gamma = 0.1)\n",
      "clf.fit(X,y)\n",
      "# test on a grid\n",
      "x1 = np.arange(-2, 8, 0.1)\n",
      "x2 = np.arange(-2, 8, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "# accuracy\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "# add the predictions as a contour\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Effect of varying parameter gamma - vary gamma from 0.001 to 20"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prepare training data\n",
      "X = np.vstack([np.array([x11,x12]).T,np.array([x21,x22]).T])\n",
      "y = np.vstack([np.ones([20,1]),-1*np.ones([20,1])])\n",
      "y = np.ravel(y)\n",
      "# vary gamma here\n",
      "clf = svm.SVC(kernel='rbf',gamma = 20)\n",
      "clf.fit(X,y)\n",
      "# test on a grid\n",
      "x1 = np.arange(-2, 8, 0.1)\n",
      "x2 = np.arange(-2, 8, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "# accuracy\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "# add the predictions as a contour\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Effect of varying penalty term (C)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate training data\n",
      "mean1 = [4,4]\n",
      "mean2 = [1,1]\n",
      "mean3 = [3,3]\n",
      "cov = [[1,-0.8],[-0.8,1]]\n",
      "cov3 = [[0.1,0],[0,0.1]]\n",
      "x11,x12 = np.random.multivariate_normal(mean1,cov,20).T\n",
      "x21,x22 = np.random.multivariate_normal(mean2,cov,20).T\n",
      "x31,x32 = np.random.multivariate_normal(mean3,cov3,4).T\n",
      "\n",
      "# prepare training data\n",
      "X = np.vstack([np.array([x11,x12]).T,np.array([x21,x22]).T,np.array([x31,x32]).T])\n",
      "y = np.vstack([np.ones([20,1]),-1*np.ones([20,1]),-1*np.ones([4,1])])\n",
      "y = np.ravel(y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# retrain SVC - this time using a linear kernel\n",
      "# Vary C here\n",
      "clf = svm.SVC(kernel='linear',C=0.01)\n",
      "clf.fit(X,y)\n",
      "x1 = np.arange(-2, 8, 0.1)\n",
      "x2 = np.arange(-2, 8, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "# accuracy\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "plt.plot(x31,x32,'bx')\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Examining SVM properties"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Coefficients (weights) and intercept"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Number of Support Vectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.support_vectors_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Case 4: Multiple Classes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate training data\n",
      "mean1 = [1,4]\n",
      "mean2 = [4,1]\n",
      "mean3 = [4,4]\n",
      "cov = [[1,-0.8],[-0.8,1]]\n",
      "x11,x12 = np.random.multivariate_normal(mean1,cov,20).T\n",
      "x21,x22 = np.random.multivariate_normal(mean2,cov,20).T\n",
      "x31,x32 = np.random.multivariate_normal(mean3,cov,20).T\n",
      "\n",
      "# prepare training data\n",
      "X = np.vstack([np.array([x11,x12]).T,np.array([x21,x22]).T,np.array([x31,x32]).T])\n",
      "y = np.vstack([np.ones([20,1]),2*np.ones([20,1]),3*np.ones([20,1])])\n",
      "y = np.ravel(y)\n",
      "# plot data\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "plt.plot(x31,x32,'rx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train multi-class classifier\n",
      "clf = svm.SVC(kernel='rbf',C=0.01,probability=True)\n",
      "clf.fit(X,y)\n",
      "x1 = np.arange(-2, 8, 0.1)\n",
      "x2 = np.arange(-2, 8, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "# accuracy\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'bx')\n",
      "plt.plot(x31,x32,'rx')\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Case 4: One Class SVM"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "One-class SVMs are useful for anomaly detection. The key parameter for learning a one-class SVM is nu which translates to the expected proportion of outliers in the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate data\n",
      "mean1 = [6,6]\n",
      "mean2 = [2,2]\n",
      "cov = [[0.5,0],[0,0.5]]\n",
      "x11,x12 = np.random.multivariate_normal(mean1,cov,1000).T\n",
      "x21,x22 = np.random.multivariate_normal(mean2,cov,1000).T\n",
      "X = np.vstack([np.array([x11,x12]).T,np.array([x21,x22]).T])\n",
      "#train a one class SVM\n",
      "clf = svm.OneClassSVM(nu=0.01,kernel='rbf',gamma=0.1)\n",
      "clf.fit(X)\n",
      "\n",
      "x1 = np.arange(-2, 10, 0.1)\n",
      "x2 = np.arange(-2, 10, 0.1)\n",
      "x1s,x2s = meshgrid(x1,x2)\n",
      "Xstar = np.array([x1s.flatten(),x2s.flatten()]).T\n",
      "ystar = clf.predict(Xstar)\n",
      "\n",
      "plt.plot(x11,x12,'kx')\n",
      "plt.plot(x21,x22,'kx')\n",
      "\n",
      "plt.contourf(x1s,x2s,np.reshape(ystar,[x1.shape[0],x2.shape[0]]),cmap=plt.cm.bone,alpha=0.6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Computational Complexity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computational complexity is $\\mathcal{O}(d \\times n^3)$ where $d$ is the number of features and $n$ is the number of training examples. Training SVMs can get expensive. Here are a few tricks that maybe used to speed it up."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate training data\n",
      "n = 50000\n",
      "mean1 = np.ravel(3*np.ones([10,1]))\n",
      "mean2 = np.ravel(np.ones([10,1]))\n",
      "cov = np.eye(10)\n",
      "x1 = np.random.multivariate_normal(mean1,cov,n)\n",
      "x2 = np.random.multivariate_normal(mean2,cov,n)\n",
      "X = np.vstack([x1,x2])\n",
      "y = np.vstack([np.ones([n,1]),-1*np.ones([n,1])])\n",
      "y = np.ravel(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Measure training time\n",
      "clf = svm.SVC(kernel='rbf',gamma = 0.1)\n",
      "s = time.time()\n",
      "clf.fit(X,y)\n",
      "e = time.time()\n",
      "print \"Execution time: %s\" % (e-s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First thing to check is if the input array is C-ordered contiguous"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.flags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.ascontiguousarray(X)\n",
      "X.flags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Measure training time\n",
      "clf = svm.SVC(kernel='rbf',gamma = 0.1)\n",
      "s = time.time()\n",
      "clf.fit(X,y)\n",
      "e = time.time()\n",
      "print \"Execution time: %s\" % (e-s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next is to play with kernel cache size. You can set the cache size as large as your memory constraints allow."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = svm.SVC(kernel='rbf',gamma = 0.1,cache_size=2048)\n",
      "s = time.time()\n",
      "clf.fit(X,y)\n",
      "e = time.time()\n",
      "print \"Execution time: %s\" % (e-s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Linear SVM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If using a linear kernel, one should use LinearSVC model which is a highly optimized version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Measure training time\n",
      "clf = svm.SVC(kernel='linear')\n",
      "s = time.time()\n",
      "clf.fit(X,y)\n",
      "e = time.time()\n",
      "print \"Execution time: %s\" % (e-s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Measure training time\n",
      "clf = svm.LinearSVC()\n",
      "s = time.time()\n",
      "clf.fit(X,y)\n",
      "e = time.time()\n",
      "print \"Execution time: %s\" % (e-s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}